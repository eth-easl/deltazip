python cli/compress_lora.py --target-model /mnt/scratch/xiayao/cache/experiments/fmzip/finetuned_lora/openllama-3b-v2/task065_timetravel_consistent_sentence_classification --outdir .cache/test/compressed_lora --dataset /mnt/scratch/xiayao/cache/datasets/qi/ar/task065_timetravel_consistent_sentence_classification.train.jsonl --n-samples 256 --bits 2 --sparsity 0 --lossless gdeflate --base-model openlm-research/open_llama_3b_v2 --perc-damp 0.01 --block-size 128 --shuffle-dataset --fast-tokenizer --delta subtract