{
    "base_model": "openlm-research/open_llama_3b_v2",
    "compressed_model_mapping": {
        ".cache/raw_models/openllama-3b-chat-1": ".cache/compressed_models/3b-parameters/openllama-chat-1",
        ".cache/raw_models/openllama-3b-chat-2": ".cache/compressed_models/3b-parameters/openllama-chat-2",
        ".cache/raw_models/openllama-3b-chat-3": ".cache/compressed_models/3b-parameters/openllama-chat-3",
        ".cache/raw_models/openllama-3b-chat-4": ".cache/compressed_models/3b-parameters/openllama-chat-4",
        ".cache/raw_models/openllama-3b-chat-5": ".cache/compressed_models/3b-parameters/openllama-chat-5",
        ".cache/raw_models/openllama-3b-chat-6": ".cache/compressed_models/3b-parameters/openllama-chat-6",
        ".cache/raw_models/openllama-3b-chat-7": ".cache/compressed_models/3b-parameters/openllama-chat-7",
        ".cache/raw_models/openllama-3b-chat-8": ".cache/compressed_models/3b-parameters/openllama-chat-8",
        ".cache/raw_models/openllama-3b-chat-9": ".cache/compressed_models/3b-parameters/openllama-chat-9",
        ".cache/raw_models/openllama-3b-chat-10": ".cache/compressed_models/3b-parameters/openllama-chat-10",
        ".cache/raw_models/openllama-3b-chat-11": ".cache/compressed_models/3b-parameters/openllama-chat-11",
        ".cache/raw_models/openllama-3b-chat-12": ".cache/compressed_models/3b-parameters/openllama-chat-12",
        ".cache/raw_models/openllama-3b-chat-13": ".cache/compressed_models/3b-parameters/openllama-chat-13",
        ".cache/raw_models/openllama-3b-chat-14": ".cache/compressed_models/3b-parameters/openllama-chat-14",
        ".cache/raw_models/openllama-3b-chat-15": ".cache/compressed_models/3b-parameters/openllama-chat-15",
        ".cache/raw_models/openllama-3b-chat-16": ".cache/compressed_models/3b-parameters/openllama-chat-16",
        ".cache/raw_models/openllama-3b-chat-17": ".cache/compressed_models/3b-parameters/openllama-chat-17",
        ".cache/raw_models/openllama-3b-chat-18": ".cache/compressed_models/3b-parameters/openllama-chat-18",
        ".cache/raw_models/openllama-3b-chat-19": ".cache/compressed_models/3b-parameters/openllama-chat-19"
    },
    "generation_configs": {
        "min_length": 64,
        "max_new_tokens": 64
    }
}